{
  "best_metric": 0.7474452554744525,
  "best_model_checkpoint": "d:\\Sarcasm Detection\\outputs\\baseline_full\\checkpoint-113712",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 113712,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004397073308006191,
      "grad_norm": 16.10238265991211,
      "learning_rate": 1.9970686177946626e-05,
      "loss": 0.6578,
      "step": 500
    },
    {
      "epoch": 0.008794146616012383,
      "grad_norm": 21.14532470703125,
      "learning_rate": 1.994137235589325e-05,
      "loss": 0.608,
      "step": 1000
    },
    {
      "epoch": 0.013191219924018574,
      "grad_norm": 12.89415454864502,
      "learning_rate": 1.9912058533839876e-05,
      "loss": 0.5992,
      "step": 1500
    },
    {
      "epoch": 0.017588293232024765,
      "grad_norm": 8.76850414276123,
      "learning_rate": 1.9882744711786504e-05,
      "loss": 0.5907,
      "step": 2000
    },
    {
      "epoch": 0.021985366540030957,
      "grad_norm": 14.79373836517334,
      "learning_rate": 1.985343088973313e-05,
      "loss": 0.5853,
      "step": 2500
    },
    {
      "epoch": 0.026382439848037148,
      "grad_norm": 11.913227081298828,
      "learning_rate": 1.9824117067679754e-05,
      "loss": 0.5757,
      "step": 3000
    },
    {
      "epoch": 0.030779513156043336,
      "grad_norm": 11.260076522827148,
      "learning_rate": 1.979480324562638e-05,
      "loss": 0.5749,
      "step": 3500
    },
    {
      "epoch": 0.03517658646404953,
      "grad_norm": 25.15863800048828,
      "learning_rate": 1.9765489423573007e-05,
      "loss": 0.5669,
      "step": 4000
    },
    {
      "epoch": 0.03957365977205572,
      "grad_norm": 15.691210746765137,
      "learning_rate": 1.973617560151963e-05,
      "loss": 0.5727,
      "step": 4500
    },
    {
      "epoch": 0.04397073308006191,
      "grad_norm": 8.571742057800293,
      "learning_rate": 1.9706861779466257e-05,
      "loss": 0.5757,
      "step": 5000
    },
    {
      "epoch": 0.048367806388068105,
      "grad_norm": 5.872710227966309,
      "learning_rate": 1.967754795741288e-05,
      "loss": 0.5628,
      "step": 5500
    },
    {
      "epoch": 0.052764879696074296,
      "grad_norm": 17.474029541015625,
      "learning_rate": 1.9648234135359506e-05,
      "loss": 0.5532,
      "step": 6000
    },
    {
      "epoch": 0.05716195300408049,
      "grad_norm": 8.46614933013916,
      "learning_rate": 1.961892031330613e-05,
      "loss": 0.5517,
      "step": 6500
    },
    {
      "epoch": 0.06155902631208667,
      "grad_norm": 10.339386940002441,
      "learning_rate": 1.9589606491252756e-05,
      "loss": 0.5549,
      "step": 7000
    },
    {
      "epoch": 0.06595609962009287,
      "grad_norm": 9.426886558532715,
      "learning_rate": 1.9560292669199384e-05,
      "loss": 0.5553,
      "step": 7500
    },
    {
      "epoch": 0.07035317292809906,
      "grad_norm": 14.531909942626953,
      "learning_rate": 1.9530978847146005e-05,
      "loss": 0.5612,
      "step": 8000
    },
    {
      "epoch": 0.07475024623610525,
      "grad_norm": 13.376687049865723,
      "learning_rate": 1.9501665025092634e-05,
      "loss": 0.55,
      "step": 8500
    },
    {
      "epoch": 0.07914731954411144,
      "grad_norm": 10.520232200622559,
      "learning_rate": 1.947235120303926e-05,
      "loss": 0.5471,
      "step": 9000
    },
    {
      "epoch": 0.08354439285211764,
      "grad_norm": 9.135151863098145,
      "learning_rate": 1.9443037380985883e-05,
      "loss": 0.5517,
      "step": 9500
    },
    {
      "epoch": 0.08794146616012383,
      "grad_norm": 10.544546127319336,
      "learning_rate": 1.9413723558932508e-05,
      "loss": 0.5645,
      "step": 10000
    },
    {
      "epoch": 0.09233853946813002,
      "grad_norm": 6.292418479919434,
      "learning_rate": 1.9384409736879136e-05,
      "loss": 0.5542,
      "step": 10500
    },
    {
      "epoch": 0.09673561277613621,
      "grad_norm": 4.757957458496094,
      "learning_rate": 1.935509591482576e-05,
      "loss": 0.5508,
      "step": 11000
    },
    {
      "epoch": 0.1011326860841424,
      "grad_norm": 10.198322296142578,
      "learning_rate": 1.9325782092772386e-05,
      "loss": 0.5372,
      "step": 11500
    },
    {
      "epoch": 0.10552975939214859,
      "grad_norm": 18.386137008666992,
      "learning_rate": 1.929646827071901e-05,
      "loss": 0.5437,
      "step": 12000
    },
    {
      "epoch": 0.10992683270015478,
      "grad_norm": 5.64822244644165,
      "learning_rate": 1.9267154448665636e-05,
      "loss": 0.5547,
      "step": 12500
    },
    {
      "epoch": 0.11432390600816097,
      "grad_norm": 13.826244354248047,
      "learning_rate": 1.923784062661226e-05,
      "loss": 0.5497,
      "step": 13000
    },
    {
      "epoch": 0.11872097931616715,
      "grad_norm": 3.0177643299102783,
      "learning_rate": 1.9208526804558885e-05,
      "loss": 0.5374,
      "step": 13500
    },
    {
      "epoch": 0.12311805262417334,
      "grad_norm": 11.514457702636719,
      "learning_rate": 1.9179212982505513e-05,
      "loss": 0.5431,
      "step": 14000
    },
    {
      "epoch": 0.12751512593217953,
      "grad_norm": 4.08184814453125,
      "learning_rate": 1.9149899160452138e-05,
      "loss": 0.5493,
      "step": 14500
    },
    {
      "epoch": 0.13191219924018574,
      "grad_norm": 16.227306365966797,
      "learning_rate": 1.9120585338398763e-05,
      "loss": 0.5474,
      "step": 15000
    },
    {
      "epoch": 0.13630927254819192,
      "grad_norm": 6.341619491577148,
      "learning_rate": 1.9091271516345388e-05,
      "loss": 0.5506,
      "step": 15500
    },
    {
      "epoch": 0.14070634585619812,
      "grad_norm": 3.819018602371216,
      "learning_rate": 1.9061957694292016e-05,
      "loss": 0.5511,
      "step": 16000
    },
    {
      "epoch": 0.1451034191642043,
      "grad_norm": 8.470325469970703,
      "learning_rate": 1.9032643872238638e-05,
      "loss": 0.5624,
      "step": 16500
    },
    {
      "epoch": 0.1495004924722105,
      "grad_norm": 14.623211860656738,
      "learning_rate": 1.9003330050185266e-05,
      "loss": 0.5509,
      "step": 17000
    },
    {
      "epoch": 0.15389756578021668,
      "grad_norm": 14.522096633911133,
      "learning_rate": 1.897401622813189e-05,
      "loss": 0.5403,
      "step": 17500
    },
    {
      "epoch": 0.1582946390882229,
      "grad_norm": 8.34521198272705,
      "learning_rate": 1.8944702406078515e-05,
      "loss": 0.5474,
      "step": 18000
    },
    {
      "epoch": 0.16269171239622907,
      "grad_norm": 11.786779403686523,
      "learning_rate": 1.891538858402514e-05,
      "loss": 0.5326,
      "step": 18500
    },
    {
      "epoch": 0.16708878570423527,
      "grad_norm": 5.619934558868408,
      "learning_rate": 1.8886074761971765e-05,
      "loss": 0.5348,
      "step": 19000
    },
    {
      "epoch": 0.17148585901224145,
      "grad_norm": 5.259317398071289,
      "learning_rate": 1.8856760939918393e-05,
      "loss": 0.5441,
      "step": 19500
    },
    {
      "epoch": 0.17588293232024765,
      "grad_norm": 7.808330059051514,
      "learning_rate": 1.8827447117865018e-05,
      "loss": 0.5394,
      "step": 20000
    },
    {
      "epoch": 0.18028000562825383,
      "grad_norm": 1.828729510307312,
      "learning_rate": 1.8798133295811643e-05,
      "loss": 0.5472,
      "step": 20500
    },
    {
      "epoch": 0.18467707893626004,
      "grad_norm": 7.6771016120910645,
      "learning_rate": 1.8768819473758268e-05,
      "loss": 0.5536,
      "step": 21000
    },
    {
      "epoch": 0.1890741522442662,
      "grad_norm": 13.306890487670898,
      "learning_rate": 1.8739505651704893e-05,
      "loss": 0.5458,
      "step": 21500
    },
    {
      "epoch": 0.19347122555227242,
      "grad_norm": 14.329146385192871,
      "learning_rate": 1.8710191829651517e-05,
      "loss": 0.5538,
      "step": 22000
    },
    {
      "epoch": 0.1978682988602786,
      "grad_norm": 4.008246898651123,
      "learning_rate": 1.8680878007598146e-05,
      "loss": 0.5333,
      "step": 22500
    },
    {
      "epoch": 0.2022653721682848,
      "grad_norm": 17.859228134155273,
      "learning_rate": 1.865156418554477e-05,
      "loss": 0.5333,
      "step": 23000
    },
    {
      "epoch": 0.20666244547629098,
      "grad_norm": 5.842654705047607,
      "learning_rate": 1.8622250363491395e-05,
      "loss": 0.5296,
      "step": 23500
    },
    {
      "epoch": 0.21105951878429718,
      "grad_norm": 14.41653823852539,
      "learning_rate": 1.859293654143802e-05,
      "loss": 0.5511,
      "step": 24000
    },
    {
      "epoch": 0.21545659209230336,
      "grad_norm": 4.503015518188477,
      "learning_rate": 1.8563622719384645e-05,
      "loss": 0.5454,
      "step": 24500
    },
    {
      "epoch": 0.21985366540030957,
      "grad_norm": 4.911384582519531,
      "learning_rate": 1.853430889733127e-05,
      "loss": 0.5495,
      "step": 25000
    },
    {
      "epoch": 0.22425073870831574,
      "grad_norm": 7.513529300689697,
      "learning_rate": 1.8504995075277898e-05,
      "loss": 0.5389,
      "step": 25500
    },
    {
      "epoch": 0.22864781201632195,
      "grad_norm": 6.642040729522705,
      "learning_rate": 1.8475681253224523e-05,
      "loss": 0.5338,
      "step": 26000
    },
    {
      "epoch": 0.23304488532432813,
      "grad_norm": 4.212671756744385,
      "learning_rate": 1.8446367431171147e-05,
      "loss": 0.5428,
      "step": 26500
    },
    {
      "epoch": 0.2374419586323343,
      "grad_norm": 42.86201095581055,
      "learning_rate": 1.8417053609117772e-05,
      "loss": 0.5378,
      "step": 27000
    },
    {
      "epoch": 0.2418390319403405,
      "grad_norm": 5.76241397857666,
      "learning_rate": 1.8387739787064397e-05,
      "loss": 0.5414,
      "step": 27500
    },
    {
      "epoch": 0.2462361052483467,
      "grad_norm": 7.597986221313477,
      "learning_rate": 1.8358425965011025e-05,
      "loss": 0.5303,
      "step": 28000
    },
    {
      "epoch": 0.25063317855635286,
      "grad_norm": 4.6899495124816895,
      "learning_rate": 1.8329112142957647e-05,
      "loss": 0.5348,
      "step": 28500
    },
    {
      "epoch": 0.25503025186435907,
      "grad_norm": 5.690488815307617,
      "learning_rate": 1.8299798320904275e-05,
      "loss": 0.5382,
      "step": 29000
    },
    {
      "epoch": 0.2594273251723653,
      "grad_norm": 5.866443157196045,
      "learning_rate": 1.82704844988509e-05,
      "loss": 0.5456,
      "step": 29500
    },
    {
      "epoch": 0.2638243984803715,
      "grad_norm": 12.43000316619873,
      "learning_rate": 1.8241170676797525e-05,
      "loss": 0.5572,
      "step": 30000
    },
    {
      "epoch": 0.26822147178837763,
      "grad_norm": 12.604355812072754,
      "learning_rate": 1.821185685474415e-05,
      "loss": 0.5521,
      "step": 30500
    },
    {
      "epoch": 0.27261854509638384,
      "grad_norm": 2.2164981365203857,
      "learning_rate": 1.8182543032690774e-05,
      "loss": 0.5444,
      "step": 31000
    },
    {
      "epoch": 0.27701561840439004,
      "grad_norm": 5.7003350257873535,
      "learning_rate": 1.8153229210637402e-05,
      "loss": 0.5512,
      "step": 31500
    },
    {
      "epoch": 0.28141269171239625,
      "grad_norm": 36.822967529296875,
      "learning_rate": 1.8123915388584027e-05,
      "loss": 0.5331,
      "step": 32000
    },
    {
      "epoch": 0.2858097650204024,
      "grad_norm": 15.342398643493652,
      "learning_rate": 1.8094601566530652e-05,
      "loss": 0.559,
      "step": 32500
    },
    {
      "epoch": 0.2902068383284086,
      "grad_norm": 13.210451126098633,
      "learning_rate": 1.8065287744477277e-05,
      "loss": 0.5339,
      "step": 33000
    },
    {
      "epoch": 0.2946039116364148,
      "grad_norm": 4.111410617828369,
      "learning_rate": 1.8035973922423905e-05,
      "loss": 0.5482,
      "step": 33500
    },
    {
      "epoch": 0.299000984944421,
      "grad_norm": 5.225286960601807,
      "learning_rate": 1.8006660100370527e-05,
      "loss": 0.5618,
      "step": 34000
    },
    {
      "epoch": 0.30339805825242716,
      "grad_norm": 4.838624954223633,
      "learning_rate": 1.7977346278317155e-05,
      "loss": 0.5502,
      "step": 34500
    },
    {
      "epoch": 0.30779513156043337,
      "grad_norm": 3.6266520023345947,
      "learning_rate": 1.794803245626378e-05,
      "loss": 0.5467,
      "step": 35000
    },
    {
      "epoch": 0.31219220486843957,
      "grad_norm": 28.52631187438965,
      "learning_rate": 1.7918718634210404e-05,
      "loss": 0.5657,
      "step": 35500
    },
    {
      "epoch": 0.3165892781764458,
      "grad_norm": 5.3708906173706055,
      "learning_rate": 1.788940481215703e-05,
      "loss": 0.5393,
      "step": 36000
    },
    {
      "epoch": 0.3209863514844519,
      "grad_norm": 12.585262298583984,
      "learning_rate": 1.7860090990103654e-05,
      "loss": 0.5381,
      "step": 36500
    },
    {
      "epoch": 0.32538342479245813,
      "grad_norm": 4.328180313110352,
      "learning_rate": 1.783077716805028e-05,
      "loss": 0.5498,
      "step": 37000
    },
    {
      "epoch": 0.32978049810046434,
      "grad_norm": 20.08994483947754,
      "learning_rate": 1.7801463345996907e-05,
      "loss": 0.5473,
      "step": 37500
    },
    {
      "epoch": 0.33417757140847054,
      "grad_norm": 10.494210243225098,
      "learning_rate": 1.7772149523943532e-05,
      "loss": 0.5394,
      "step": 38000
    },
    {
      "epoch": 0.3385746447164767,
      "grad_norm": 11.335219383239746,
      "learning_rate": 1.7742835701890157e-05,
      "loss": 0.5422,
      "step": 38500
    },
    {
      "epoch": 0.3429717180244829,
      "grad_norm": 7.310627460479736,
      "learning_rate": 1.771352187983678e-05,
      "loss": 0.5612,
      "step": 39000
    },
    {
      "epoch": 0.3473687913324891,
      "grad_norm": 1.660744547843933,
      "learning_rate": 1.7684208057783406e-05,
      "loss": 0.5931,
      "step": 39500
    },
    {
      "epoch": 0.3517658646404953,
      "grad_norm": 13.63072395324707,
      "learning_rate": 1.7654894235730035e-05,
      "loss": 0.5906,
      "step": 40000
    },
    {
      "epoch": 0.35616293794850146,
      "grad_norm": 6.712850093841553,
      "learning_rate": 1.7625580413676656e-05,
      "loss": 0.5573,
      "step": 40500
    },
    {
      "epoch": 0.36056001125650766,
      "grad_norm": 15.438429832458496,
      "learning_rate": 1.7596266591623284e-05,
      "loss": 0.5758,
      "step": 41000
    },
    {
      "epoch": 0.36495708456451387,
      "grad_norm": 4.093373775482178,
      "learning_rate": 1.756695276956991e-05,
      "loss": 0.5623,
      "step": 41500
    },
    {
      "epoch": 0.3693541578725201,
      "grad_norm": 5.594182014465332,
      "learning_rate": 1.7537638947516534e-05,
      "loss": 0.5534,
      "step": 42000
    },
    {
      "epoch": 0.3737512311805262,
      "grad_norm": 70.36799621582031,
      "learning_rate": 1.750832512546316e-05,
      "loss": 0.559,
      "step": 42500
    },
    {
      "epoch": 0.3781483044885324,
      "grad_norm": 12.74493408203125,
      "learning_rate": 1.7479011303409787e-05,
      "loss": 0.5336,
      "step": 43000
    },
    {
      "epoch": 0.38254537779653863,
      "grad_norm": 6.730343341827393,
      "learning_rate": 1.744969748135641e-05,
      "loss": 0.5485,
      "step": 43500
    },
    {
      "epoch": 0.38694245110454484,
      "grad_norm": 7.61268949508667,
      "learning_rate": 1.7420383659303036e-05,
      "loss": 0.5569,
      "step": 44000
    },
    {
      "epoch": 0.391339524412551,
      "grad_norm": 22.03912925720215,
      "learning_rate": 1.739106983724966e-05,
      "loss": 0.5586,
      "step": 44500
    },
    {
      "epoch": 0.3957365977205572,
      "grad_norm": 5.981062412261963,
      "learning_rate": 1.7361756015196286e-05,
      "loss": 0.541,
      "step": 45000
    },
    {
      "epoch": 0.4001336710285634,
      "grad_norm": 5.022045135498047,
      "learning_rate": 1.7332442193142914e-05,
      "loss": 0.5719,
      "step": 45500
    },
    {
      "epoch": 0.4045307443365696,
      "grad_norm": 52.3754768371582,
      "learning_rate": 1.7303128371089536e-05,
      "loss": 0.558,
      "step": 46000
    },
    {
      "epoch": 0.40892781764457575,
      "grad_norm": 4.643350124359131,
      "learning_rate": 1.7273814549036164e-05,
      "loss": 0.5599,
      "step": 46500
    },
    {
      "epoch": 0.41332489095258196,
      "grad_norm": 16.152191162109375,
      "learning_rate": 1.724450072698279e-05,
      "loss": 0.5463,
      "step": 47000
    },
    {
      "epoch": 0.41772196426058816,
      "grad_norm": 4.530374050140381,
      "learning_rate": 1.7215186904929414e-05,
      "loss": 0.531,
      "step": 47500
    },
    {
      "epoch": 0.42211903756859437,
      "grad_norm": 3.6815121173858643,
      "learning_rate": 1.718587308287604e-05,
      "loss": 0.5354,
      "step": 48000
    },
    {
      "epoch": 0.4265161108766005,
      "grad_norm": 21.64809226989746,
      "learning_rate": 1.7156559260822667e-05,
      "loss": 0.5354,
      "step": 48500
    },
    {
      "epoch": 0.4309131841846067,
      "grad_norm": 4.70950984954834,
      "learning_rate": 1.7127245438769288e-05,
      "loss": 0.5443,
      "step": 49000
    },
    {
      "epoch": 0.43531025749261293,
      "grad_norm": 12.579290390014648,
      "learning_rate": 1.7097931616715916e-05,
      "loss": 0.5373,
      "step": 49500
    },
    {
      "epoch": 0.43970733080061913,
      "grad_norm": 5.780561923980713,
      "learning_rate": 1.706861779466254e-05,
      "loss": 0.5376,
      "step": 50000
    },
    {
      "epoch": 0.4441044041086253,
      "grad_norm": 2.402400493621826,
      "learning_rate": 1.7039303972609166e-05,
      "loss": 0.5447,
      "step": 50500
    },
    {
      "epoch": 0.4485014774166315,
      "grad_norm": 4.992504596710205,
      "learning_rate": 1.700999015055579e-05,
      "loss": 0.5457,
      "step": 51000
    },
    {
      "epoch": 0.4528985507246377,
      "grad_norm": 3.238271713256836,
      "learning_rate": 1.6980676328502415e-05,
      "loss": 0.5398,
      "step": 51500
    },
    {
      "epoch": 0.4572956240326439,
      "grad_norm": 9.454764366149902,
      "learning_rate": 1.6951362506449044e-05,
      "loss": 0.5563,
      "step": 52000
    },
    {
      "epoch": 0.46169269734065005,
      "grad_norm": 2.385955810546875,
      "learning_rate": 1.6922048684395665e-05,
      "loss": 0.5567,
      "step": 52500
    },
    {
      "epoch": 0.46608977064865625,
      "grad_norm": 11.145878791809082,
      "learning_rate": 1.6892734862342293e-05,
      "loss": 0.5259,
      "step": 53000
    },
    {
      "epoch": 0.47048684395666246,
      "grad_norm": 6.780707836151123,
      "learning_rate": 1.6863421040288918e-05,
      "loss": 0.5434,
      "step": 53500
    },
    {
      "epoch": 0.4748839172646686,
      "grad_norm": 5.413635730743408,
      "learning_rate": 1.6834107218235546e-05,
      "loss": 0.5291,
      "step": 54000
    },
    {
      "epoch": 0.4792809905726748,
      "grad_norm": 4.460791110992432,
      "learning_rate": 1.6804793396182168e-05,
      "loss": 0.5459,
      "step": 54500
    },
    {
      "epoch": 0.483678063880681,
      "grad_norm": 8.466111183166504,
      "learning_rate": 1.6775479574128796e-05,
      "loss": 0.5294,
      "step": 55000
    },
    {
      "epoch": 0.4880751371886872,
      "grad_norm": 6.748472690582275,
      "learning_rate": 1.674616575207542e-05,
      "loss": 0.529,
      "step": 55500
    },
    {
      "epoch": 0.4924722104966934,
      "grad_norm": 37.749053955078125,
      "learning_rate": 1.6716851930022046e-05,
      "loss": 0.5314,
      "step": 56000
    },
    {
      "epoch": 0.4968692838046996,
      "grad_norm": 5.334331035614014,
      "learning_rate": 1.668753810796867e-05,
      "loss": 0.5372,
      "step": 56500
    },
    {
      "epoch": 0.5012663571127057,
      "grad_norm": 9.814000129699707,
      "learning_rate": 1.6658224285915295e-05,
      "loss": 0.5337,
      "step": 57000
    },
    {
      "epoch": 0.5056634304207119,
      "grad_norm": 7.834160804748535,
      "learning_rate": 1.6628910463861923e-05,
      "loss": 0.5523,
      "step": 57500
    },
    {
      "epoch": 0.5100605037287181,
      "grad_norm": 1.569204568862915,
      "learning_rate": 1.6599596641808545e-05,
      "loss": 0.5577,
      "step": 58000
    },
    {
      "epoch": 0.5144575770367243,
      "grad_norm": 1.9723289012908936,
      "learning_rate": 1.6570282819755173e-05,
      "loss": 0.564,
      "step": 58500
    },
    {
      "epoch": 0.5188546503447306,
      "grad_norm": 27.5350399017334,
      "learning_rate": 1.6540968997701798e-05,
      "loss": 0.5722,
      "step": 59000
    },
    {
      "epoch": 0.5232517236527368,
      "grad_norm": 8.505680084228516,
      "learning_rate": 1.6511655175648423e-05,
      "loss": 0.5525,
      "step": 59500
    },
    {
      "epoch": 0.527648796960743,
      "grad_norm": 2.4597957134246826,
      "learning_rate": 1.6482341353595048e-05,
      "loss": 0.5566,
      "step": 60000
    },
    {
      "epoch": 0.5320458702687492,
      "grad_norm": 4.619011402130127,
      "learning_rate": 1.6453027531541676e-05,
      "loss": 0.5605,
      "step": 60500
    },
    {
      "epoch": 0.5364429435767553,
      "grad_norm": 10.093810081481934,
      "learning_rate": 1.64237137094883e-05,
      "loss": 0.5482,
      "step": 61000
    },
    {
      "epoch": 0.5408400168847615,
      "grad_norm": 90.4350357055664,
      "learning_rate": 1.6394399887434925e-05,
      "loss": 0.5537,
      "step": 61500
    },
    {
      "epoch": 0.5452370901927677,
      "grad_norm": 10.22619915008545,
      "learning_rate": 1.636508606538155e-05,
      "loss": 0.5392,
      "step": 62000
    },
    {
      "epoch": 0.5496341635007739,
      "grad_norm": 3.843352794647217,
      "learning_rate": 1.6335772243328175e-05,
      "loss": 0.5457,
      "step": 62500
    },
    {
      "epoch": 0.5540312368087801,
      "grad_norm": 28.394519805908203,
      "learning_rate": 1.63064584212748e-05,
      "loss": 0.5326,
      "step": 63000
    },
    {
      "epoch": 0.5584283101167863,
      "grad_norm": 13.262115478515625,
      "learning_rate": 1.6277144599221425e-05,
      "loss": 0.5303,
      "step": 63500
    },
    {
      "epoch": 0.5628253834247925,
      "grad_norm": 1.493016004562378,
      "learning_rate": 1.6247830777168053e-05,
      "loss": 0.5313,
      "step": 64000
    },
    {
      "epoch": 0.5672224567327987,
      "grad_norm": 5.441362380981445,
      "learning_rate": 1.6218516955114674e-05,
      "loss": 0.5361,
      "step": 64500
    },
    {
      "epoch": 0.5716195300408048,
      "grad_norm": 56.641090393066406,
      "learning_rate": 1.6189203133061303e-05,
      "loss": 0.5437,
      "step": 65000
    },
    {
      "epoch": 0.576016603348811,
      "grad_norm": 61.777076721191406,
      "learning_rate": 1.6159889311007927e-05,
      "loss": 0.5739,
      "step": 65500
    },
    {
      "epoch": 0.5804136766568172,
      "grad_norm": 9.777847290039062,
      "learning_rate": 1.6130575488954556e-05,
      "loss": 0.5705,
      "step": 66000
    },
    {
      "epoch": 0.5848107499648234,
      "grad_norm": 6.483413219451904,
      "learning_rate": 1.6101261666901177e-05,
      "loss": 0.5554,
      "step": 66500
    },
    {
      "epoch": 0.5892078232728296,
      "grad_norm": 10.216031074523926,
      "learning_rate": 1.6071947844847805e-05,
      "loss": 0.5508,
      "step": 67000
    },
    {
      "epoch": 0.5936048965808358,
      "grad_norm": 2.597787857055664,
      "learning_rate": 1.604263402279443e-05,
      "loss": 0.5555,
      "step": 67500
    },
    {
      "epoch": 0.598001969888842,
      "grad_norm": 13.603822708129883,
      "learning_rate": 1.6013320200741055e-05,
      "loss": 0.5559,
      "step": 68000
    },
    {
      "epoch": 0.6023990431968482,
      "grad_norm": 8.096362113952637,
      "learning_rate": 1.598400637868768e-05,
      "loss": 0.5565,
      "step": 68500
    },
    {
      "epoch": 0.6067961165048543,
      "grad_norm": 3.56840443611145,
      "learning_rate": 1.5954692556634304e-05,
      "loss": 0.5516,
      "step": 69000
    },
    {
      "epoch": 0.6111931898128605,
      "grad_norm": 2.039788246154785,
      "learning_rate": 1.5925378734580933e-05,
      "loss": 0.5573,
      "step": 69500
    },
    {
      "epoch": 0.6155902631208667,
      "grad_norm": 1.5770798921585083,
      "learning_rate": 1.5896064912527554e-05,
      "loss": 0.5561,
      "step": 70000
    },
    {
      "epoch": 0.6199873364288729,
      "grad_norm": 4.879302501678467,
      "learning_rate": 1.5866751090474182e-05,
      "loss": 0.5448,
      "step": 70500
    },
    {
      "epoch": 0.6243844097368791,
      "grad_norm": 17.072219848632812,
      "learning_rate": 1.5837437268420807e-05,
      "loss": 0.5563,
      "step": 71000
    },
    {
      "epoch": 0.6287814830448853,
      "grad_norm": 10.506272315979004,
      "learning_rate": 1.5808123446367432e-05,
      "loss": 0.554,
      "step": 71500
    },
    {
      "epoch": 0.6331785563528916,
      "grad_norm": 3.6002604961395264,
      "learning_rate": 1.5778809624314057e-05,
      "loss": 0.5314,
      "step": 72000
    },
    {
      "epoch": 0.6375756296608978,
      "grad_norm": 3.7738916873931885,
      "learning_rate": 1.5749495802260685e-05,
      "loss": 0.5353,
      "step": 72500
    },
    {
      "epoch": 0.6419727029689039,
      "grad_norm": 6.61513614654541,
      "learning_rate": 1.572018198020731e-05,
      "loss": 0.5435,
      "step": 73000
    },
    {
      "epoch": 0.6463697762769101,
      "grad_norm": 1.9893622398376465,
      "learning_rate": 1.5690868158153935e-05,
      "loss": 0.5379,
      "step": 73500
    },
    {
      "epoch": 0.6507668495849163,
      "grad_norm": 2.388944149017334,
      "learning_rate": 1.566155433610056e-05,
      "loss": 0.5476,
      "step": 74000
    },
    {
      "epoch": 0.6551639228929225,
      "grad_norm": 5.160058498382568,
      "learning_rate": 1.5632240514047184e-05,
      "loss": 0.5467,
      "step": 74500
    },
    {
      "epoch": 0.6595609962009287,
      "grad_norm": 7.376406192779541,
      "learning_rate": 1.560292669199381e-05,
      "loss": 0.5448,
      "step": 75000
    },
    {
      "epoch": 0.6639580695089349,
      "grad_norm": 66.33251190185547,
      "learning_rate": 1.5573612869940434e-05,
      "loss": 0.5455,
      "step": 75500
    },
    {
      "epoch": 0.6683551428169411,
      "grad_norm": 2.8095974922180176,
      "learning_rate": 1.5544299047887062e-05,
      "loss": 0.5406,
      "step": 76000
    },
    {
      "epoch": 0.6727522161249473,
      "grad_norm": 10.146880149841309,
      "learning_rate": 1.5514985225833687e-05,
      "loss": 0.5459,
      "step": 76500
    },
    {
      "epoch": 0.6771492894329534,
      "grad_norm": 14.650792121887207,
      "learning_rate": 1.548567140378031e-05,
      "loss": 0.5595,
      "step": 77000
    },
    {
      "epoch": 0.6815463627409596,
      "grad_norm": 6.8442840576171875,
      "learning_rate": 1.5456357581726937e-05,
      "loss": 0.5391,
      "step": 77500
    },
    {
      "epoch": 0.6859434360489658,
      "grad_norm": 7.056739330291748,
      "learning_rate": 1.5427043759673565e-05,
      "loss": 0.5466,
      "step": 78000
    },
    {
      "epoch": 0.690340509356972,
      "grad_norm": 5.539918422698975,
      "learning_rate": 1.5397729937620186e-05,
      "loss": 0.552,
      "step": 78500
    },
    {
      "epoch": 0.6947375826649782,
      "grad_norm": 4.7791428565979,
      "learning_rate": 1.5368416115566814e-05,
      "loss": 0.5318,
      "step": 79000
    },
    {
      "epoch": 0.6991346559729844,
      "grad_norm": 37.21333312988281,
      "learning_rate": 1.533910229351344e-05,
      "loss": 0.5531,
      "step": 79500
    },
    {
      "epoch": 0.7035317292809906,
      "grad_norm": 6.087508201599121,
      "learning_rate": 1.5309788471460064e-05,
      "loss": 0.5349,
      "step": 80000
    },
    {
      "epoch": 0.7079288025889967,
      "grad_norm": 3.572744369506836,
      "learning_rate": 1.528047464940669e-05,
      "loss": 0.5427,
      "step": 80500
    },
    {
      "epoch": 0.7123258758970029,
      "grad_norm": 9.932648658752441,
      "learning_rate": 1.5251160827353315e-05,
      "loss": 0.5669,
      "step": 81000
    },
    {
      "epoch": 0.7167229492050091,
      "grad_norm": 7.024425983428955,
      "learning_rate": 1.5221847005299942e-05,
      "loss": 0.5705,
      "step": 81500
    },
    {
      "epoch": 0.7211200225130153,
      "grad_norm": 7.045307636260986,
      "learning_rate": 1.5192533183246565e-05,
      "loss": 0.5474,
      "step": 82000
    },
    {
      "epoch": 0.7255170958210215,
      "grad_norm": 5.152991771697998,
      "learning_rate": 1.5163219361193191e-05,
      "loss": 0.5562,
      "step": 82500
    },
    {
      "epoch": 0.7299141691290277,
      "grad_norm": 18.036466598510742,
      "learning_rate": 1.5133905539139816e-05,
      "loss": 0.5354,
      "step": 83000
    },
    {
      "epoch": 0.7343112424370339,
      "grad_norm": 1.9240756034851074,
      "learning_rate": 1.5104591717086441e-05,
      "loss": 0.5671,
      "step": 83500
    },
    {
      "epoch": 0.7387083157450401,
      "grad_norm": 6.204875946044922,
      "learning_rate": 1.5075277895033068e-05,
      "loss": 0.5646,
      "step": 84000
    },
    {
      "epoch": 0.7431053890530462,
      "grad_norm": 8.217890739440918,
      "learning_rate": 1.5045964072979692e-05,
      "loss": 0.5405,
      "step": 84500
    },
    {
      "epoch": 0.7475024623610524,
      "grad_norm": 4.4240217208862305,
      "learning_rate": 1.5016650250926319e-05,
      "loss": 0.5788,
      "step": 85000
    },
    {
      "epoch": 0.7518995356690586,
      "grad_norm": 8.42997932434082,
      "learning_rate": 1.4987336428872942e-05,
      "loss": 0.5328,
      "step": 85500
    },
    {
      "epoch": 0.7562966089770649,
      "grad_norm": 4.968165397644043,
      "learning_rate": 1.4958022606819569e-05,
      "loss": 0.5419,
      "step": 86000
    },
    {
      "epoch": 0.7606936822850711,
      "grad_norm": 7.935583114624023,
      "learning_rate": 1.4928708784766195e-05,
      "loss": 0.541,
      "step": 86500
    },
    {
      "epoch": 0.7650907555930773,
      "grad_norm": 32.832698822021484,
      "learning_rate": 1.4899394962712818e-05,
      "loss": 0.5438,
      "step": 87000
    },
    {
      "epoch": 0.7694878289010835,
      "grad_norm": 107.09083557128906,
      "learning_rate": 1.4870081140659445e-05,
      "loss": 0.5349,
      "step": 87500
    },
    {
      "epoch": 0.7738849022090897,
      "grad_norm": 7.383637428283691,
      "learning_rate": 1.4840767318606071e-05,
      "loss": 0.5554,
      "step": 88000
    },
    {
      "epoch": 0.7782819755170958,
      "grad_norm": 9.894816398620605,
      "learning_rate": 1.4811453496552696e-05,
      "loss": 0.5325,
      "step": 88500
    },
    {
      "epoch": 0.782679048825102,
      "grad_norm": 8.737370491027832,
      "learning_rate": 1.4782139674499321e-05,
      "loss": 0.5345,
      "step": 89000
    },
    {
      "epoch": 0.7870761221331082,
      "grad_norm": 4.829423904418945,
      "learning_rate": 1.4752825852445947e-05,
      "loss": 0.5299,
      "step": 89500
    },
    {
      "epoch": 0.7914731954411144,
      "grad_norm": 5.346202373504639,
      "learning_rate": 1.4723512030392572e-05,
      "loss": 0.5581,
      "step": 90000
    },
    {
      "epoch": 0.7958702687491206,
      "grad_norm": 52.38899230957031,
      "learning_rate": 1.4694198208339197e-05,
      "loss": 0.5279,
      "step": 90500
    },
    {
      "epoch": 0.8002673420571268,
      "grad_norm": 3.337007522583008,
      "learning_rate": 1.4664884386285822e-05,
      "loss": 0.5262,
      "step": 91000
    },
    {
      "epoch": 0.804664415365133,
      "grad_norm": 6.98732328414917,
      "learning_rate": 1.4635570564232448e-05,
      "loss": 0.5362,
      "step": 91500
    },
    {
      "epoch": 0.8090614886731392,
      "grad_norm": 6.12302827835083,
      "learning_rate": 1.4606256742179073e-05,
      "loss": 0.5353,
      "step": 92000
    },
    {
      "epoch": 0.8134585619811453,
      "grad_norm": 4.585868835449219,
      "learning_rate": 1.4576942920125698e-05,
      "loss": 0.533,
      "step": 92500
    },
    {
      "epoch": 0.8178556352891515,
      "grad_norm": 2.313876152038574,
      "learning_rate": 1.4547629098072324e-05,
      "loss": 0.562,
      "step": 93000
    },
    {
      "epoch": 0.8222527085971577,
      "grad_norm": 97.51795959472656,
      "learning_rate": 1.4518315276018951e-05,
      "loss": 0.5678,
      "step": 93500
    },
    {
      "epoch": 0.8266497819051639,
      "grad_norm": 17.308008193969727,
      "learning_rate": 1.4489001453965574e-05,
      "loss": 0.5494,
      "step": 94000
    },
    {
      "epoch": 0.8310468552131701,
      "grad_norm": 6.365790367126465,
      "learning_rate": 1.44596876319122e-05,
      "loss": 0.5543,
      "step": 94500
    },
    {
      "epoch": 0.8354439285211763,
      "grad_norm": 62.36254119873047,
      "learning_rate": 1.4430373809858827e-05,
      "loss": 0.5329,
      "step": 95000
    },
    {
      "epoch": 0.8398410018291825,
      "grad_norm": 7.853355407714844,
      "learning_rate": 1.440105998780545e-05,
      "loss": 0.528,
      "step": 95500
    },
    {
      "epoch": 0.8442380751371887,
      "grad_norm": 2.999161720275879,
      "learning_rate": 1.4371746165752077e-05,
      "loss": 0.5336,
      "step": 96000
    },
    {
      "epoch": 0.8486351484451948,
      "grad_norm": 1.729049563407898,
      "learning_rate": 1.4342432343698702e-05,
      "loss": 0.5233,
      "step": 96500
    },
    {
      "epoch": 0.853032221753201,
      "grad_norm": 4.152891635894775,
      "learning_rate": 1.4313118521645328e-05,
      "loss": 0.5558,
      "step": 97000
    },
    {
      "epoch": 0.8574292950612072,
      "grad_norm": 8.22642707824707,
      "learning_rate": 1.4283804699591953e-05,
      "loss": 0.56,
      "step": 97500
    },
    {
      "epoch": 0.8618263683692134,
      "grad_norm": 87.15044403076172,
      "learning_rate": 1.4254490877538578e-05,
      "loss": 0.5415,
      "step": 98000
    },
    {
      "epoch": 0.8662234416772197,
      "grad_norm": 15.650408744812012,
      "learning_rate": 1.4225177055485204e-05,
      "loss": 0.5661,
      "step": 98500
    },
    {
      "epoch": 0.8706205149852259,
      "grad_norm": 13.030996322631836,
      "learning_rate": 1.4195863233431827e-05,
      "loss": 0.5483,
      "step": 99000
    },
    {
      "epoch": 0.8750175882932321,
      "grad_norm": 16.422826766967773,
      "learning_rate": 1.4166549411378454e-05,
      "loss": 0.5579,
      "step": 99500
    },
    {
      "epoch": 0.8794146616012383,
      "grad_norm": 3.974818468093872,
      "learning_rate": 1.413723558932508e-05,
      "loss": 0.5524,
      "step": 100000
    },
    {
      "epoch": 0.8838117349092444,
      "grad_norm": 67.67200469970703,
      "learning_rate": 1.4107921767271707e-05,
      "loss": 0.544,
      "step": 100500
    },
    {
      "epoch": 0.8882088082172506,
      "grad_norm": 3.324514865875244,
      "learning_rate": 1.407860794521833e-05,
      "loss": 0.5649,
      "step": 101000
    },
    {
      "epoch": 0.8926058815252568,
      "grad_norm": 2.4737792015075684,
      "learning_rate": 1.4049294123164957e-05,
      "loss": 0.5477,
      "step": 101500
    },
    {
      "epoch": 0.897002954833263,
      "grad_norm": 13.133896827697754,
      "learning_rate": 1.4019980301111581e-05,
      "loss": 0.5301,
      "step": 102000
    },
    {
      "epoch": 0.9014000281412692,
      "grad_norm": 8.610488891601562,
      "learning_rate": 1.3990666479058206e-05,
      "loss": 0.5324,
      "step": 102500
    },
    {
      "epoch": 0.9057971014492754,
      "grad_norm": 8.272149085998535,
      "learning_rate": 1.3961352657004833e-05,
      "loss": 0.555,
      "step": 103000
    },
    {
      "epoch": 0.9101941747572816,
      "grad_norm": 8.298799514770508,
      "learning_rate": 1.3932038834951458e-05,
      "loss": 0.5346,
      "step": 103500
    },
    {
      "epoch": 0.9145912480652878,
      "grad_norm": 105.24739837646484,
      "learning_rate": 1.3902725012898082e-05,
      "loss": 0.534,
      "step": 104000
    },
    {
      "epoch": 0.9189883213732939,
      "grad_norm": 1.9403334856033325,
      "learning_rate": 1.3873411190844707e-05,
      "loss": 0.5341,
      "step": 104500
    },
    {
      "epoch": 0.9233853946813001,
      "grad_norm": 3.193643569946289,
      "learning_rate": 1.3844097368791334e-05,
      "loss": 0.5388,
      "step": 105000
    },
    {
      "epoch": 0.9277824679893063,
      "grad_norm": 1.4785889387130737,
      "learning_rate": 1.381478354673796e-05,
      "loss": 0.5326,
      "step": 105500
    },
    {
      "epoch": 0.9321795412973125,
      "grad_norm": 5.860851764678955,
      "learning_rate": 1.3785469724684583e-05,
      "loss": 0.5482,
      "step": 106000
    },
    {
      "epoch": 0.9365766146053187,
      "grad_norm": 38.235618591308594,
      "learning_rate": 1.375615590263121e-05,
      "loss": 0.5265,
      "step": 106500
    },
    {
      "epoch": 0.9409736879133249,
      "grad_norm": 3.556523084640503,
      "learning_rate": 1.3726842080577836e-05,
      "loss": 0.5353,
      "step": 107000
    },
    {
      "epoch": 0.9453707612213311,
      "grad_norm": 12.311854362487793,
      "learning_rate": 1.369752825852446e-05,
      "loss": 0.5242,
      "step": 107500
    },
    {
      "epoch": 0.9497678345293372,
      "grad_norm": 2.64849853515625,
      "learning_rate": 1.3668214436471086e-05,
      "loss": 0.5471,
      "step": 108000
    },
    {
      "epoch": 0.9541649078373434,
      "grad_norm": 8.624571800231934,
      "learning_rate": 1.363890061441771e-05,
      "loss": 0.5382,
      "step": 108500
    },
    {
      "epoch": 0.9585619811453496,
      "grad_norm": 4.15562629699707,
      "learning_rate": 1.3609586792364337e-05,
      "loss": 0.5222,
      "step": 109000
    },
    {
      "epoch": 0.9629590544533558,
      "grad_norm": 3.0646257400512695,
      "learning_rate": 1.3580272970310962e-05,
      "loss": 0.5401,
      "step": 109500
    },
    {
      "epoch": 0.967356127761362,
      "grad_norm": 7.104803085327148,
      "learning_rate": 1.3550959148257587e-05,
      "loss": 0.5345,
      "step": 110000
    },
    {
      "epoch": 0.9717532010693682,
      "grad_norm": 11.038168907165527,
      "learning_rate": 1.3521645326204213e-05,
      "loss": 0.5497,
      "step": 110500
    },
    {
      "epoch": 0.9761502743773744,
      "grad_norm": 96.446533203125,
      "learning_rate": 1.3492331504150837e-05,
      "loss": 0.5412,
      "step": 111000
    },
    {
      "epoch": 0.9805473476853807,
      "grad_norm": 34.697265625,
      "learning_rate": 1.3463017682097463e-05,
      "loss": 0.5353,
      "step": 111500
    },
    {
      "epoch": 0.9849444209933867,
      "grad_norm": 5.343205451965332,
      "learning_rate": 1.343370386004409e-05,
      "loss": 0.5328,
      "step": 112000
    },
    {
      "epoch": 0.989341494301393,
      "grad_norm": 3.607635259628296,
      "learning_rate": 1.3404390037990716e-05,
      "loss": 0.5298,
      "step": 112500
    },
    {
      "epoch": 0.9937385676093992,
      "grad_norm": 14.063156127929688,
      "learning_rate": 1.337507621593734e-05,
      "loss": 0.5308,
      "step": 113000
    },
    {
      "epoch": 0.9981356409174054,
      "grad_norm": 64.68863677978516,
      "learning_rate": 1.3345762393883966e-05,
      "loss": 0.528,
      "step": 113500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7535368725142959,
      "eval_f1": 0.7474452554744525,
      "eval_loss": 0.5419355034828186,
      "eval_precision": 0.7663555287611999,
      "eval_recall": 0.7294457526168946,
      "eval_runtime": 42.3608,
      "eval_samples_per_second": 2386.119,
      "eval_steps_per_second": 149.147,
      "step": 113712
    }
  ],
  "logging_steps": 500,
  "max_steps": 341136,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.458594471491148e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
